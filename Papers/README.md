### 2024-04-11 [Manipulating Large Language Models to Increase Product Visibility](https://arxiv.org/abs/2404.07981)
### 2024-06-16 [Rethinking Kull-Leibler Divergence in Knowledge Distillation for Large Language Models](https://arxiv.org/abs/2404.02657)
### 2021-05-19 [Comparing Kullback-Leibler Divergence and Mean Squared Error Loss in Knowledge Distillation](https://arxiv.org/abs/2105.08919)
### 2023-11-12 [Large Language Models Understand and Can be Enhanced by Emotional Stimuli](https://arxiv.org/abs/2307.11760)
